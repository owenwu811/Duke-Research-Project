{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scopus\n",
    "from scopus import AuthorSearch\n",
    "\n",
    "scopus.load_api_key()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_author_pubs(first, last, affil):\n",
    "    s = AuthorSearch('AUTHLASTNAME(' + last + ') and AUTHFIRST(' + first + ') and AFFIL(' + affil + ')', refresh=True)\n",
    "    \n",
    "    if(len(s.authors)==0):\n",
    "        print(\"Narrowing search to name only\")\n",
    "        s = AuthorSearch('AUTHLASTNAME(' + first + ') and AUTHFIRST(' + last + ')', refresh=True)\n",
    "        \n",
    "        if(s._json==[]):\n",
    "            print(\"Found no results..\")\n",
    "            return None\n",
    "    \n",
    "    print(str(len(s.authors)) + \" author(s) found\")\n",
    "    sAuthor = scopus.ScopusAuthor(s.authors[0].eid)\n",
    "    \n",
    "    return sAuthor.get_abstracts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 author(s) found\n"
     ]
    }
   ],
   "source": [
    "pubs = search_author_pubs(\"Ehab\", \"Abouheif\", \"McGill\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = vars(test)\n",
    "raw['xml'] = None\n",
    "raw['_authors'] = [x.given_name + \" \" + x.surname for x in test.authors]\n",
    "raw['_affiliations'] = [x.affilname for x in test.affiliations]\n",
    "json.dumps(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = ScopusSearch('TITLE( Fuzzy logic approach for layered architecture cognitive radio systems )', count=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_EIDS': ['2-s2.0-85049989127'],\n",
       " 'query': 'TITLE( Fuzzy logic approach for layered architecture cognitive radio systems )'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ab = ScopusAbstract('2-s2.0-0035934588')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PubMed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib3\n",
    "import datetime\n",
    "\n",
    "_SESSION = requests.session()\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "proxy_port = \"8010\"\n",
    "proxy_host = \"proxy.crawlera.com\"\n",
    "proxy_auth = \":\" # Make sure to include ':' at the end\n",
    "proxies = {\"https\": \"https://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port),\n",
    "      \"http\": \"http://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url, retry=0):\n",
    "    global _SESSION\n",
    "    \n",
    "    if retry==5:\n",
    "        return None\n",
    "    \n",
    "    response = _SESSION.get(url, proxies=proxies, verify=False)\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        return response.content\n",
    "    else:\n",
    "        print(str(response.status_code) + \" Code, waiting 10s before retrying\")\n",
    "        time.sleep(10)\n",
    "        _SESSION = requests.Session()\n",
    "        return get_page_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed(query):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=1000&term=\"\n",
    "    end_url = \"&field=title\"\n",
    "    \n",
    "    full_url = base_url + query.replace(\" \", \"%20\") + end_url\n",
    "    \n",
    "    content = get_page_content(full_url)\n",
    "    \n",
    "    if content==None:\n",
    "        return []\n",
    "    \n",
    "    x = json.loads(content)\n",
    "    \n",
    "    try:\n",
    "        return x['esearchresult']['idlist']\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pubmed_pub(pubid):\n",
    "    full_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?retmode=json&db=pubmed&id=\" + pubid\n",
    "\n",
    "    content = get_page_content(full_url)\n",
    "    \n",
    "    if content==None:\n",
    "        return []\n",
    "    \n",
    "    x = json.loads(content)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_author_pubs(name, affilation):\n",
    "    pub_ids = search_pubmed(\"(\" + name + \"[Author]) AND \" + affilation + \"[Affiliation]\")\n",
    "\n",
    "    pubs = []\n",
    "    for pub_id in pub_ids:\n",
    "        pubs.append(get_pubmed_pub(pub_id))\n",
    "        \n",
    "    return pubs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['26062690', '25944476', '25903435', '25407924', '24889934', '24870037', '24151998', '24118264', '24026822', '23676760', '23565668', '22988083', '22907523', '22834738', '21436104', '20707851']\n"
     ]
    }
   ],
   "source": [
    "x = get_author_pubs(\"Jeremy Beaulieu\", \"Yale University\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "for pub in x:\n",
    "    stripped_pub = list(pub['result'].values())[1]\n",
    "    title = stripped_pub['title']\n",
    "    authors = \" and \".join([y['name'] for y in stripped_pub['authors']])\n",
    "    year = int(stripped_pub['pubdate'][0:4])\n",
    "    journal = stripped_pub['fulljournalname']\n",
    "    raw = json.dumps(pub)\n",
    "    cited_by = stripped_pub.get('pmcrefcount')\n",
    "    date = datetime.datetime.today().strftime('%Y-%m-%d')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cited_by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining Data Sets\n",
    "Combine data sets with Google Scholar ID and without for PubMed, Scopus, and WoS scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_scholar_id = pd.read_csv(\"turk_grouped.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "scholar_id = pd.read_excel(\"NESCent Google Scholar IDs.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(180, 16)"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_scholar_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(441, 7)"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scholar_id.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.DataFrame(columns=[\"NameLast\", \"NameFirst\", \"institution_name\", \"profession_role\", \"dept_current\"])\n",
    "for index, row in scholar_id.iterrows():\n",
    "    new_row = dict()\n",
    "    new_row[\"NameFirst\"] = row.NameFirst\n",
    "    new_row[\"NameLast\"] = row.NameLast\n",
    "    new_row[\"institution_name\"] = row.institution_name\n",
    "    new_row[\"profession_role\"] = row.profession_role\n",
    "    new_row[\"dept_current\"] = row.dept_current\n",
    "    \n",
    "    combined_df = combined_df.append(new_row, ignore_index=True)\n",
    "    \n",
    "for index, row in no_scholar_id.iterrows():\n",
    "    new_row = dict()\n",
    "    \n",
    "    name_split = row[\"Input.name\"].split(\" \")\n",
    "    \n",
    "    new_row[\"NameFirst\"] = \" \".join(str(x) for x in name_split[0:-1])\n",
    "    new_row[\"NameLast\"] = name_split[-1]\n",
    "    new_row[\"institution_name\"] = row['Input.university']\n",
    "    new_row[\"profession_role\"] = row['Input.discipline']\n",
    "    new_row[\"dept_current\"] = row['Input.department']\n",
    "    \n",
    "    combined_df = combined_df.append(new_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"all_researchers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
