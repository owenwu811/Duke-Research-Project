{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from difflib import SequenceMatcher\n",
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import urllib3\n",
    "import datetime\n",
    "\n",
    "_SESSION = requests.session()\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "proxy_port = \"8010\"\n",
    "proxy_host = \"proxy.crawlera.com\"\n",
    "proxy_auth = \":\" # Make sure to include ':' at the end\n",
    "proxies = {\"https\": \"https://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port),\n",
    "      \"http\": \"http://{}@{}:{}/\".format(proxy_auth, proxy_host, proxy_port)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nescent_df = pd.read_csv(\"turk_grouped_with_middle_initial_only.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scraped_df = pd.read_csv(\"NESCent_No_ID.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_content(url, retry=0):\n",
    "    global _SESSION\n",
    "    \n",
    "    if retry==5:\n",
    "        return None\n",
    "    \n",
    "    response = _SESSION.get(url, proxies=proxies, verify=False)\n",
    "    \n",
    "    if response.status_code==200:\n",
    "        return response.content\n",
    "    else:\n",
    "        print(str(response.status_code) + \" Code, waiting 10s before retrying\")\n",
    "        time.sleep(10)\n",
    "        _SESSION = requests.Session()\n",
    "        return get_page_content(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar(a, b):\n",
    "    return SequenceMatcher(None, a, b).ratio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_pubmed(query):\n",
    "    base_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi?db=pubmed&retmode=json&retmax=3&term=\"\n",
    "    end_url = \"&field=title\"\n",
    "    \n",
    "    full_url = base_url + query.replace(\" \", \"%20\") + end_url\n",
    "    \n",
    "    content = get_page_content(full_url)\n",
    "    \n",
    "    if content==None:\n",
    "        return []\n",
    "    \n",
    "    x = json.loads(content)\n",
    "    \n",
    "    try:\n",
    "        return x['esearchresult']['idlist']\n",
    "    except KeyError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pubmed_pub(pubid):\n",
    "    full_url = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi?retmode=json&db=pubmed&id=\" + pubid\n",
    "\n",
    "    content = get_page_content(full_url)\n",
    "    \n",
    "    if content==None:\n",
    "        return []\n",
    "    \n",
    "    x = json.loads(content)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_scopus(query):\n",
    "    search = 'Title(' + query + ')'\n",
    "    s = scopus.ScopusSearch(search, refresh=True, count=10)\n",
    "    return s._EIDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scopus_pub(pubid):\n",
    "    try:\n",
    "        return ScopusAbstract(pubid)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_pubmed(base_row, pub):\n",
    "    print(\"\\t\\tChecking PubMed..\")\n",
    "    \n",
    "    pubmed_info = None\n",
    "    pubmed_id = None\n",
    "    ids = search_pubmed(pub)\n",
    "\n",
    "    for pub_id in ids:\n",
    "        pubmed_json = get_pubmed_pub(pub_id)\n",
    "        if similar(pubmed_json[\"result\"][pub_id][\"title\"], pub) > threshold:\n",
    "            pubmed_match = True\n",
    "            pubmed_info = pubmed_json\n",
    "            pubmed_id = pub_id\n",
    "            break\n",
    "\n",
    "    if pubmed_info:\n",
    "        print(\"\\t\\tFound new publication\")\n",
    "        new_row = base_row[:]\n",
    "        new_row.append(pubmed_info[\"result\"][pubmed_id][\"title\"])\n",
    "        new_row.append(\" and \".join([z['name'] for z in pubmed_info[\"result\"][pubmed_id][\"authors\"]]))\n",
    "        new_row.append(int(pubmed_info['result'][pubmed_id]['pubdate'][0:4]))\n",
    "        new_row.append(pubmed_info[\"result\"][pubmed_id][\"source\"])\n",
    "        new_row.append(json.dumps(pubmed_info))\n",
    "        new_row.append(datetime.datetime.today().strftime('%Y-%m-%d'))\n",
    "        new_row.append(pubmed_info[\"result\"][pubmed_id][\"pmcrefcount\"])\n",
    "        new_row.append(\"Pub Med\")\n",
    "        \n",
    "        return new_row\n",
    "    \n",
    "    return None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scopus\n",
    "from scopus import ScopusAbstract\n",
    "scopus.load_api_key()\n",
    "\n",
    "def check_scopus(base_row, pub):\n",
    "    print(\"\\t\\tChecking Scopus..\")\n",
    "    \n",
    "    scopus_info = None\n",
    "    scopus_id = None\n",
    "    ids = search_scopus(pub)\n",
    "\n",
    "    for pub_id in ids:\n",
    "        try:\n",
    "            scopus_json = get_scopus_pub(pub_id)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if scopus_json==None:\n",
    "            continue\n",
    "        \n",
    "        if similar(scopus_json.title, pub) > threshold:\n",
    "            pubmed_match = True\n",
    "            scopus_info = scopus_json\n",
    "            scopus_id = pub_id\n",
    "            break\n",
    "\n",
    "    if scopus_info:\n",
    "        print(\"\\t\\tFound new publication\")\n",
    "        new_row = base_row[:]\n",
    "        new_row.append(scopus_info.title)\n",
    "        new_row.append(\" and \".join([z['name'] for z in scopus_info.authors[0].given_name]))\n",
    "        new_row.append(int(scopus_info.coverDate[0:4]))\n",
    "        new_row.append(scopus_info.publicationName)\n",
    "        new_row.append(json.dumps(scopus_info))\n",
    "        new_row.append(datetime.datetime.today().strftime('%Y-%m-%d'))\n",
    "        new_row.append(scopus_info.citedby_count)\n",
    "        new_row.append(\"Scopus\")\n",
    "        \n",
    "        return new_row\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "threshold = .9\n",
    "\n",
    "new_scraped_df = pd.DataFrame(columns=scraped_df.columns)\n",
    "# new_scraped_df = pd.read_csv(\"pub_med_cv.csv\", index_col=0)\n",
    "\n",
    "for i, row in nescent_df.iterrows():\n",
    "    clear_output()\n",
    "    print(\"Author \" + str(i) + \" of \" + str(nescent_df.shape[0]))\n",
    "\n",
    "    unconfirmed_pubs = row.unconfirmed_publications\n",
    "    scholar_pubs = list(scraped_df[scraped_df[\"initials\"] == row[\"Google Scholar Middle Initial\"]]['publication'])\n",
    "\n",
    "    initials = row[\"Google Scholar Middle Initial\"]\n",
    "    name = row[\"Input.name\"]\n",
    "    name = name.replace('-', ' ')\n",
    "    name_split = name.split()\n",
    "\n",
    "    base_row = [name, initials, row[\"Input.university\"], row[\"Input.department\"], row[\"Input.discipline\"]]\n",
    "\n",
    "    checked_ids = []\n",
    "    if not isinstance(unconfirmed_pubs, float):\n",
    "        unconfirmed_pubs_split = set(unconfirmed_pubs.split(', '))\n",
    "        for j, pub in enumerate(unconfirmed_pubs_split):\n",
    "            print(\"\\tPublication \" + str(j) + \" of \" + str(len(unconfirmed_pubs_split)))\n",
    "            already_have = False\n",
    "\n",
    "            # Check if already have\n",
    "            for scholar_pub in scholar_pubs:\n",
    "                if similar(scholar_pub, pub) > threshold:\n",
    "                    # Already captured by Google Scholar\n",
    "                    already_have = True\n",
    "                    print(\"\\t\\tAlready in GS\")\n",
    "                    break\n",
    "\n",
    "            found_match = False\n",
    "            if not already_have:\n",
    "                # Search in other sources\n",
    "\n",
    "                # Start with pubmed\n",
    "                new_row = check_pubmed(base_row, pub)\n",
    "\n",
    "                if new_row is None:\n",
    "                    new_row = check_scopus(base_row, pub)\n",
    "\n",
    "            if new_row is not None:\n",
    "                new_scraped_df.loc[new_scraped_df.shape[0]] = new_row    \n",
    "\n",
    "    new_scraped_df.to_csv(\"pub_med_cv.csv\")\n",
    "\n",
    "\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
